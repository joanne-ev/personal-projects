{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84f39348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b658d44a",
   "metadata": {},
   "source": [
    "# Scikit-Learn's Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0db34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37b4a7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ed8107e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>price</th><th>area</th><th>bedrooms</th><th>bathrooms</th><th>stories</th><th>mainroad</th><th>guestroom</th><th>basement</th><th>hotwaterheating</th><th>airconditioning</th><th>parking</th><th>prefarea</th><th>furnishingstatus</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>13300000</td><td>7420</td><td>4</td><td>2</td><td>3</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>2</td><td>&quot;yes&quot;</td><td>&quot;furnished&quot;</td></tr><tr><td>12250000</td><td>8960</td><td>4</td><td>4</td><td>4</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>3</td><td>&quot;no&quot;</td><td>&quot;furnished&quot;</td></tr><tr><td>12250000</td><td>9960</td><td>3</td><td>2</td><td>2</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;no&quot;</td><td>2</td><td>&quot;yes&quot;</td><td>&quot;semi-furnished&quot;</td></tr><tr><td>12215000</td><td>7500</td><td>4</td><td>2</td><td>2</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>3</td><td>&quot;yes&quot;</td><td>&quot;furnished&quot;</td></tr><tr><td>11410000</td><td>7420</td><td>4</td><td>1</td><td>2</td><td>&quot;yes&quot;</td><td>&quot;yes&quot;</td><td>&quot;yes&quot;</td><td>&quot;no&quot;</td><td>&quot;yes&quot;</td><td>2</td><td>&quot;no&quot;</td><td>&quot;furnished&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌──────────┬──────┬──────────┬───────────┬───┬────────────────┬─────────┬──────────┬───────────────┐\n",
       "│ price    ┆ area ┆ bedrooms ┆ bathrooms ┆ … ┆ airconditionin ┆ parking ┆ prefarea ┆ furnishingsta │\n",
       "│ ---      ┆ ---  ┆ ---      ┆ ---       ┆   ┆ g              ┆ ---     ┆ ---      ┆ tus           │\n",
       "│ i64      ┆ i64  ┆ i64      ┆ i64       ┆   ┆ ---            ┆ i64     ┆ str      ┆ ---           │\n",
       "│          ┆      ┆          ┆           ┆   ┆ str            ┆         ┆          ┆ str           │\n",
       "╞══════════╪══════╪══════════╪═══════════╪═══╪════════════════╪═════════╪══════════╪═══════════════╡\n",
       "│ 13300000 ┆ 7420 ┆ 4        ┆ 2         ┆ … ┆ yes            ┆ 2       ┆ yes      ┆ furnished     │\n",
       "│ 12250000 ┆ 8960 ┆ 4        ┆ 4         ┆ … ┆ yes            ┆ 3       ┆ no       ┆ furnished     │\n",
       "│ 12250000 ┆ 9960 ┆ 3        ┆ 2         ┆ … ┆ no             ┆ 2       ┆ yes      ┆ semi-furnishe │\n",
       "│          ┆      ┆          ┆           ┆   ┆                ┆         ┆          ┆ d             │\n",
       "│ 12215000 ┆ 7500 ┆ 4        ┆ 2         ┆ … ┆ yes            ┆ 3       ┆ yes      ┆ furnished     │\n",
       "│ 11410000 ┆ 7420 ┆ 4        ┆ 1         ┆ … ┆ yes            ┆ 2       ┆ no       ┆ furnished     │\n",
       "└──────────┴──────┴──────────┴───────────┴───┴────────────────┴─────────┴──────────┴───────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pl.read_csv(\"Housing.csv\")\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aca6f0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 16)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>mainroad_no</th><th>mainroad_yes</th><th>guestroom_no</th><th>guestroom_yes</th><th>basement_no</th><th>basement_yes</th><th>hotwaterheating_no</th><th>hotwaterheating_yes</th><th>airconditioning_no</th><th>airconditioning_yes</th><th>prefarea_no</th><th>prefarea_yes</th><th>furnishingstatus_furnished</th><th>furnishingstatus_semi-furnished</th><th>furnishingstatus_unfurnished</th></tr><tr><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>2</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>3</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>4</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 16)\n",
       "┌───────┬────────────┬────────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ index ┆ mainroad_n ┆ mainroad_y ┆ guestroom_ ┆ … ┆ prefarea_ ┆ furnishin ┆ furnishin ┆ furnishin │\n",
       "│ ---   ┆ o          ┆ es         ┆ no         ┆   ┆ yes       ┆ gstatus_f ┆ gstatus_s ┆ gstatus_u │\n",
       "│ u32   ┆ ---        ┆ ---        ┆ ---        ┆   ┆ ---       ┆ urnished  ┆ emi-furni ┆ nfurnishe │\n",
       "│       ┆ i64        ┆ i64        ┆ i64        ┆   ┆ i64       ┆ ---       ┆ she…      ┆ d         │\n",
       "│       ┆            ┆            ┆            ┆   ┆           ┆ i64       ┆ ---       ┆ ---       │\n",
       "│       ┆            ┆            ┆            ┆   ┆           ┆           ┆ i64       ┆ i64       │\n",
       "╞═══════╪════════════╪════════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0     ┆ 0          ┆ 1          ┆ 1          ┆ … ┆ 1         ┆ 1         ┆ 0         ┆ 0         │\n",
       "│ 1     ┆ 0          ┆ 1          ┆ 1          ┆ … ┆ 0         ┆ 1         ┆ 0         ┆ 0         │\n",
       "│ 2     ┆ 0          ┆ 1          ┆ 1          ┆ … ┆ 1         ┆ 0         ┆ 1         ┆ 0         │\n",
       "│ 3     ┆ 0          ┆ 1          ┆ 1          ┆ … ┆ 1         ┆ 1         ┆ 0         ┆ 0         │\n",
       "│ 4     ┆ 0          ┆ 1          ┆ 0          ┆ … ┆ 0         ┆ 1         ┆ 0         ┆ 0         │\n",
       "└───────┴────────────┴────────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_cols = housing.select(pl.col(pl.String)).columns\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded_array = encoder.fit_transform(housing[categorical_cols]).toarray().astype('int64')\n",
    "encoder_features = encoder.get_feature_names_out().tolist()\n",
    "\n",
    "housing_cat = pl.DataFrame(\n",
    "    encoded_array,\n",
    "    schema=encoder_features\n",
    ").with_row_index(name=\"index\")\n",
    "\n",
    "housing_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7f93c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 7)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>price</th><th>area</th><th>bedrooms</th><th>bathrooms</th><th>stories</th><th>parking</th></tr><tr><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>13300000</td><td>7420</td><td>4</td><td>2</td><td>3</td><td>2</td></tr><tr><td>1</td><td>12250000</td><td>8960</td><td>4</td><td>4</td><td>4</td><td>3</td></tr><tr><td>2</td><td>12250000</td><td>9960</td><td>3</td><td>2</td><td>2</td><td>2</td></tr><tr><td>3</td><td>12215000</td><td>7500</td><td>4</td><td>2</td><td>2</td><td>3</td></tr><tr><td>4</td><td>11410000</td><td>7420</td><td>4</td><td>1</td><td>2</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 7)\n",
       "┌───────┬──────────┬──────┬──────────┬───────────┬─────────┬─────────┐\n",
       "│ index ┆ price    ┆ area ┆ bedrooms ┆ bathrooms ┆ stories ┆ parking │\n",
       "│ ---   ┆ ---      ┆ ---  ┆ ---      ┆ ---       ┆ ---     ┆ ---     │\n",
       "│ u32   ┆ i64      ┆ i64  ┆ i64      ┆ i64       ┆ i64     ┆ i64     │\n",
       "╞═══════╪══════════╪══════╪══════════╪═══════════╪═════════╪═════════╡\n",
       "│ 0     ┆ 13300000 ┆ 7420 ┆ 4        ┆ 2         ┆ 3       ┆ 2       │\n",
       "│ 1     ┆ 12250000 ┆ 8960 ┆ 4        ┆ 4         ┆ 4       ┆ 3       │\n",
       "│ 2     ┆ 12250000 ┆ 9960 ┆ 3        ┆ 2         ┆ 2       ┆ 2       │\n",
       "│ 3     ┆ 12215000 ┆ 7500 ┆ 4        ┆ 2         ┆ 2       ┆ 3       │\n",
       "│ 4     ┆ 11410000 ┆ 7420 ┆ 4        ┆ 1         ┆ 2       ┆ 2       │\n",
       "└───────┴──────────┴──────┴──────────┴───────────┴─────────┴─────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_int = housing.clone().select(pl.col(pl.Int64)).with_row_index(name=\"index\")\n",
    "housing_int.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4992492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = housing_int.join(\n",
    "    other=housing_cat,\n",
    "    on=\"index\", \n",
    "    how=\"left\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca095c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "x = housing_df[:, 2:].to_numpy()\n",
    "y = housing_df[:, 0].to_numpy().reshape(-1, 1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "732fa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardisation\n",
    "x_scaler = StandardScaler()\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "x_test_scaled = x_scaler.transform(x_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0626c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Best Fold Results ###\n",
      "Score (MSE): 0.254\n",
      "Intercept: 269.75\n",
      "Coefficients: [4554.13    2.92    1.2     1.58    0.55    0.15    0.85    0.84    0.16\n",
      "    0.7     0.3     0.96    0.04    0.72    0.28    0.79    0.21    0.24\n",
      "    0.36    0.39]\n"
     ]
    }
   ],
   "source": [
    "# Linear regression model\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x_train_scaled, y_train_scaled)\n",
    "\n",
    "# Cross validation\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=state)\n",
    "\n",
    "# Applying the linear regression model on each fold\n",
    "cv_results = cross_validate(\n",
    "    lin_reg, \n",
    "    x_train_scaled, y_train_scaled,\n",
    "    scoring=\"neg_mean_squared_error\", \n",
    "    cv=cv,\n",
    "    return_estimator=True\n",
    ")\n",
    "\n",
    "# Identify which fold produced the best score\n",
    "best_fold_idx = cv_results['test_score'].round(3).argmax()\n",
    "\n",
    "# Get the fitted model corresponding to the best fold\n",
    "best_estimator = cv_results['estimator'][best_fold_idx]\n",
    "\n",
    "# Extract the results\n",
    "coefficients_scaled = best_estimator.coef_[0]\n",
    "intercept_scaled = best_estimator.intercept_[0]\n",
    "mse = -(cv_results['test_score'][best_fold_idx])\n",
    "\n",
    "# Intercept\n",
    "intercept_reshaped = intercept_scaled.reshape(1, -1)\n",
    "intercept = y_scaler.inverse_transform(intercept_reshaped)[0, 0].round(2)\n",
    "\n",
    "# Coefficients\n",
    "coefficients_reshaped = coefficients_scaled.reshape(1, -1)\n",
    "coefficients = x_scaler.inverse_transform(coefficients_reshaped)[0].round(3)\n",
    "\n",
    "## Final Results\n",
    "np.set_printoptions(suppress=True, precision=3)\n",
    "\n",
    "print(\"### Best Fold Results ###\")\n",
    "print(f\"Score (MSE): {mse.round(3)}\")\n",
    "print(f\"Intercept: {intercept.round(3):,}\")\n",
    "print(f\"Coefficients: {coefficients.round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c69519ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test MSE: 0.3492\n",
      "Final test R-squared score: 0.6392\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = best_estimator.predict(x_test_scaled)\n",
    "\n",
    "final_mse = mean_squared_error(y_test_scaled, y_pred_test)\n",
    "final_r2_score = best_estimator.score(x_test_scaled, y_test_scaled)\n",
    "\n",
    "print(f\"Final test MSE: {final_mse:.4f}\")\n",
    "print(f\"Final test R-squared score: {final_r2_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ef8245",
   "metadata": {},
   "source": [
    "# PyTorch's Linear Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bafc836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdad3447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 22)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>price</th><th>area</th><th>bedrooms</th><th>bathrooms</th><th>stories</th><th>parking</th><th>mainroad_no</th><th>mainroad_yes</th><th>guestroom_no</th><th>guestroom_yes</th><th>basement_no</th><th>basement_yes</th><th>hotwaterheating_no</th><th>hotwaterheating_yes</th><th>airconditioning_no</th><th>airconditioning_yes</th><th>prefarea_no</th><th>prefarea_yes</th><th>furnishingstatus_furnished</th><th>furnishingstatus_semi-furnished</th><th>furnishingstatus_unfurnished</th></tr><tr><td>u32</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>0</td><td>13300000</td><td>7420</td><td>4</td><td>2</td><td>3</td><td>2</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>1</td><td>12250000</td><td>8960</td><td>4</td><td>4</td><td>4</td><td>3</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr><tr><td>2</td><td>12250000</td><td>9960</td><td>3</td><td>2</td><td>2</td><td>2</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr><tr><td>3</td><td>12215000</td><td>7500</td><td>4</td><td>2</td><td>2</td><td>3</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td></tr><tr><td>4</td><td>11410000</td><td>7420</td><td>4</td><td>1</td><td>2</td><td>2</td><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 22)\n",
       "┌───────┬──────────┬──────┬──────────┬───┬──────────────┬──────────────┬─────────────┬─────────────┐\n",
       "│ index ┆ price    ┆ area ┆ bedrooms ┆ … ┆ prefarea_yes ┆ furnishingst ┆ furnishings ┆ furnishings │\n",
       "│ ---   ┆ ---      ┆ ---  ┆ ---      ┆   ┆ ---          ┆ atus_furnish ┆ tatus_semi- ┆ tatus_unfur │\n",
       "│ u32   ┆ i64      ┆ i64  ┆ i64      ┆   ┆ i64          ┆ ed           ┆ furnishe…   ┆ nished      │\n",
       "│       ┆          ┆      ┆          ┆   ┆              ┆ ---          ┆ ---         ┆ ---         │\n",
       "│       ┆          ┆      ┆          ┆   ┆              ┆ i64          ┆ i64         ┆ i64         │\n",
       "╞═══════╪══════════╪══════╪══════════╪═══╪══════════════╪══════════════╪═════════════╪═════════════╡\n",
       "│ 0     ┆ 13300000 ┆ 7420 ┆ 4        ┆ … ┆ 1            ┆ 1            ┆ 0           ┆ 0           │\n",
       "│ 1     ┆ 12250000 ┆ 8960 ┆ 4        ┆ … ┆ 0            ┆ 1            ┆ 0           ┆ 0           │\n",
       "│ 2     ┆ 12250000 ┆ 9960 ┆ 3        ┆ … ┆ 1            ┆ 0            ┆ 1           ┆ 0           │\n",
       "│ 3     ┆ 12215000 ┆ 7500 ┆ 4        ┆ … ┆ 1            ┆ 1            ┆ 0           ┆ 0           │\n",
       "│ 4     ┆ 11410000 ┆ 7420 ┆ 4        ┆ … ┆ 0            ┆ 1            ┆ 0           ┆ 0           │\n",
       "└───────┴──────────┴──────┴──────────┴───┴──────────────┴──────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b6fcd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = housing_df[:, 2:].to_numpy()\n",
    "Y = housing_df[:, 1].to_numpy().reshape(-1, 1)\n",
    "\n",
    "X_train, X_val_test, Y_train, Y_val_test = train_test_split(X, Y, test_size=0.25, random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7dd9ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = X_val_test.shape[0]\n",
    "test_indices = np.arange(nrows) \n",
    "\n",
    "np.random.seed(state)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "test_val_split = round(nrows * 0.50)\n",
    "val_idx = test_indices[:test_val_split] \n",
    "test_idx = test_indices[test_val_split:] \n",
    "\n",
    "X_test, Y_test = X_val_test[test_idx], Y_val_test[test_idx]\n",
    "X_val, Y_val = X_val_test[val_idx], Y_val_test[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c65ea964",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_train_scaled = X_scaler.fit_transform(X_train)\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "\n",
    "X_val_scaled = X_scaler.transform(X_val)\n",
    "X_val_tensor = torch.tensor(X_val_scaled, dtype=torch.float32)\n",
    "\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "Y_scaler = StandardScaler()\n",
    "Y_train_scaled = Y_scaler.fit_transform(Y_train)\n",
    "Y_train_tensor = torch.tensor(Y_train_scaled, dtype=torch.float32)\n",
    "\n",
    "Y_val_scaled = Y_scaler.transform(Y_val)\n",
    "Y_val_tensor = torch.tensor(Y_val_scaled, dtype=torch.float32)\n",
    "\n",
    "Y_test_scaled = Y_scaler.transform(Y_test)\n",
    "Y_test_tensor = torch.tensor(Y_test_scaled, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a2b890f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "validation_data = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "testing_data = TensorDataset(X_test_tensor, Y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5cf6e106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designing model architecture\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()  # Inherit constructor from parent class (nn.Module) to initialise the parent class\n",
    "\n",
    "        # Build sequential layer\n",
    "        self.sequential_layer = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),  # 50% of the input features will be randomly set to zero\n",
    "            nn.Linear(input_size, 10),  # Linear layer 1\n",
    "            nn.ReLU(),  # Rectified linear unit (activation function)\n",
    "            nn.Linear(10, output_size),  # Linear layer 2\n",
    "        )\n",
    "\n",
    "    # The forward pass simply calls the sequential container\n",
    "    def forward(self, x):\n",
    "        return self.sequential_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b08aafdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    # Initialise trainer with the core components\n",
    "    def __init__(self, model, loss_criterion, optimiser):\n",
    "        self.model = model\n",
    "        self.loss_criterion = loss_criterion\n",
    "        self.optimiser = optimiser\n",
    "\n",
    "    # Behaviours within a singular training step\n",
    "    def training_step(self, x, y):\n",
    "        # Set model to training mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Forward pass (i.e., create prediction based on features)\n",
    "        y_hat = self.model(x)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = self.loss_criterion(y_hat, y)\n",
    "\n",
    "        # Backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimisation\n",
    "        self.optimiser.step()\n",
    "\n",
    "        # Reset gradient to zero\n",
    "        self.optimiser.zero_grad()\n",
    "\n",
    "        return loss.item()\n",
    "\n",
    "    # Trains the model over multiple epochs using the provided loaded data\n",
    "    def training_process(self, loaded_training_tensor, epochs, print_loss = True):\n",
    "        training_loss = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            train_batch_losses = []\n",
    "\n",
    "            for x_train_batch, y_train_batch in loaded_training_tensor:\n",
    "                x_train_batch = x_train_batch.to(device)\n",
    "                y_train_batch = y_train_batch.to(device)\n",
    "\n",
    "                train_batch_loss = self.training_step(x_train_batch, y_train_batch)\n",
    "                train_batch_losses.append(train_batch_loss)\n",
    "\n",
    "            training_loss.append(torch.tensor(train_batch_losses).mean().item())\n",
    "\n",
    "            if print_loss == True:\n",
    "                if epoch == 0:\n",
    "                    print(f\"Epoch {epoch}/{epochs} | Train Loss: {training_loss[-1]:.3f}\")\n",
    "                if (epoch + 1) % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch + 1}/{epochs} | Train Loss: {training_loss[-1]:.3f}\"\n",
    "                    )\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        return training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb361861",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Validation ###\n",
    "class ModelValidation:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def validation_process(self, loaded_validation_tensor, loss_criterion, epochs, print_loss = True):\n",
    "        validation_loss = []\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            with torch.no_grad():\n",
    "                val_batch_losses = []\n",
    "\n",
    "                for x_val_batch, y_val_batch in loaded_validation_tensor:\n",
    "                    x_val_batch = x_val_batch.to(device) # Move validation data to the device\n",
    "                    y_val_batch = y_val_batch.to(device) # Move validation data to the device\n",
    "\n",
    "                    self.model.eval()\n",
    "\n",
    "                    y_hat = self.model(x_val_batch)\n",
    "                    val_batch_loss = loss_criterion(y_hat, y_val_batch).item()\n",
    "                    val_batch_losses.append(val_batch_loss)\n",
    "\n",
    "                validation_loss.append(torch.tensor(val_batch_losses).mean().item())\n",
    "\n",
    "            if print_loss == True:\n",
    "                if epoch == 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch} / {epochs} | Validation loss: {validation_loss[-1]:.3f}\"\n",
    "                    )\n",
    "                if (epoch + 1) % 1000 == 0:\n",
    "                    print(\n",
    "                        f\"Epoch {epoch + 1}/{epochs} | Validation loss: {validation_loss[-1]:.3f}\"\n",
    "                    )\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        return validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c745d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4856a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTesting:\n",
    "    def __init__(self, model, loss_criterion):\n",
    "        self.model = model\n",
    "        self.loss_criterion = loss_criterion\n",
    "        \n",
    "    def testing_process(self, test_batches):\n",
    "        with torch.no_grad():\n",
    "            test_batch_losses = []\n",
    "\n",
    "            for x_test_batch, y_test_batch in test_batches:\n",
    "                x_test_batch = x_test_batch.to(device) # Move validation data to the device\n",
    "                y_test_batch = y_test_batch.to(device) # Move validation data to the device\n",
    "\n",
    "                self.model.eval()\n",
    "\n",
    "                y_hat = self.model(x_test_batch)\n",
    "                test_batch_loss = self.loss_criterion(y_hat, y_test_batch).item()\n",
    "                test_batch_losses.append(test_batch_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43afdc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing parameters: {'batch_size': 8, 'lr': 0.001, 'weight_decay': 0.001}\n",
      "Testing parameters: {'batch_size': 8, 'lr': 0.001, 'weight_decay': 0.01}\n",
      "Testing parameters: {'batch_size': 8, 'lr': 0.01, 'weight_decay': 0.001}\n",
      "Testing parameters: {'batch_size': 8, 'lr': 0.01, 'weight_decay': 0.01}\n",
      "Testing parameters: {'batch_size': 16, 'lr': 0.001, 'weight_decay': 0.001}\n",
      "Testing parameters: {'batch_size': 16, 'lr': 0.001, 'weight_decay': 0.01}\n",
      "Testing parameters: {'batch_size': 16, 'lr': 0.01, 'weight_decay': 0.001}\n",
      "Testing parameters: {'batch_size': 16, 'lr': 0.01, 'weight_decay': 0.01}\n"
     ]
    }
   ],
   "source": [
    "### Hyperparameter tuning ###\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'lr': [0.001, 0.01],\n",
    "    'weight_decay': [0.001, 0.01],\n",
    "    'batch_size': [8, 16]\n",
    "}\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "# Perform grid search to find the best parameters\n",
    "best_params = None\n",
    "best_loss = float('inf')  # Initialise best_loss as infinity\n",
    "\n",
    "# Go through a grid with all possible combinations of the specified hyperparameters\n",
    "for params in ParameterGrid(param_grid):\n",
    "    print(f\"Testing parameters: {params}\")\n",
    "\n",
    "    # Get data loaders for current batch size\n",
    "    batched_train_tuning = DataLoader(dataset=training_data, batch_size=params['batch_size'], shuffle=True)\n",
    "    batched_val_tuning = DataLoader(dataset=testing_data, batch_size=params['batch_size'], shuffle=True)\n",
    "\n",
    "    # Initialise model, loss function, and optimiser with current parameters\n",
    "    model = LinearModel(input_size=X.shape[1], output_size=1)\n",
    "    model.to(device) # Move the model to the device (if on cuda)\n",
    "\n",
    "    loss_criterion = nn.MSELoss(reduction=\"mean\")\n",
    "    optimiser = optim.SGD(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    # Train the model\n",
    "    model_trainer = ModelTrainer(\n",
    "        model=model,\n",
    "        loss_criterion=loss_criterion,\n",
    "        optimiser=optimiser\n",
    "    )\n",
    "\n",
    "    train_loss = model_trainer.training_process(\n",
    "        loaded_training_tensor=batched_train_tuning,\n",
    "        epochs=n_epochs,\n",
    "        print_loss = False\n",
    "    )\n",
    "\n",
    "    # Validate the model\n",
    "    # model_validation = ModelValidation(model=model)\n",
    "\n",
    "    # val_loss = model_validation.validation_process(\n",
    "    #     loaded_validation_tensor=batched_val_tuning,\n",
    "    #     loss_criterion=loss_criterion,\n",
    "    #     epochs=n_epochs,\n",
    "    #     print_loss = False\n",
    "    # )\n",
    "\n",
    "    val_loss_mean = np.mean(val_loss).item()\n",
    "\n",
    "    # Update best parameters if current validation loss is lower\n",
    "    if val_loss_mean < best_loss:\n",
    "        best_loss = val_loss_mean\n",
    "        best_params = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "710f3438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters: {'batch_size': 16, 'lr': 0.01, 'weight_decay': 0.01} with the lowest loss of 0.376\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best parameters: {best_params} with the lowest loss of {best_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c23d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
